{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corona Virus Tweets Sentiment Analysis\n",
    "\n",
    "## Table of Content\n",
    "<ul>\n",
    "    <li><a href=\"#i\">Import Packages.</a></li>\n",
    "    <li><a href=\"#dw\">Data Wrangling.</a></li>\n",
    "    <li><a href=\"#ds\">Deep Learning.</a></li>\n",
    "    <li><a href=\"#s\">Model Saving.</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"i\"></a>\n",
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T09:59:10.098092Z",
     "iopub.status.busy": "2022-05-13T09:59:10.097811Z",
     "iopub.status.idle": "2022-05-13T09:59:18.400588Z",
     "shell.execute_reply": "2022-05-13T09:59:18.399112Z",
     "shell.execute_reply.started": "2022-05-13T09:59:10.098069Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dw\"></a>\n",
    "## Data Wrangling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T09:59:33.394855Z",
     "iopub.status.busy": "2022-05-13T09:59:33.394347Z",
     "iopub.status.idle": "2022-05-13T09:59:33.721857Z",
     "shell.execute_reply": "2022-05-13T09:59:33.720739Z",
     "shell.execute_reply.started": "2022-05-13T09:59:33.394823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName   Location     TweetAt  \\\n",
       "0      3799       48751     London  16-03-2020   \n",
       "1      3800       48752         UK  16-03-2020   \n",
       "2      3801       48753  Vagabonds  16-03-2020   \n",
       "3      3802       48754        NaN  16-03-2020   \n",
       "4      3803       48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1  advice Talk to your neighbours family to excha...            Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3  My food stock is not the only one which is emp...            Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\ameer\\Downloads\\Corona_NLP_train.csv/Corona_NLP_train.csv\", encoding='latin-1')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T09:59:56.720661Z",
     "iopub.status.busy": "2022-05-13T09:59:56.720394Z",
     "iopub.status.idle": "2022-05-13T09:59:56.732552Z",
     "shell.execute_reply": "2022-05-13T09:59:56.731789Z",
     "shell.execute_reply.started": "2022-05-13T09:59:56.720637Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[['OriginalTweet', 'Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T10:01:57.704109Z",
     "iopub.status.busy": "2022-05-13T10:01:57.703855Z",
     "iopub.status.idle": "2022-05-13T10:01:58.242368Z",
     "shell.execute_reply": "2022-05-13T10:01:58.240638Z",
     "shell.execute_reply.started": "2022-05-13T10:01:57.704084Z"
    }
   },
   "outputs": [],
   "source": [
    "df['OriginalTweet'] = df['OriginalTweet'].apply(lambda x: x.lower())\n",
    "df['OriginalTweet'] = df['OriginalTweet'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T10:02:11.687468Z",
     "iopub.status.busy": "2022-05-13T10:02:11.687183Z",
     "iopub.status.idle": "2022-05-13T10:02:11.695891Z",
     "shell.execute_reply": "2022-05-13T10:02:11.694552Z",
     "shell.execute_reply.started": "2022-05-13T10:02:11.687438Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_users(tweet):\n",
    "    \"\"\"Takes a string and removes retweet and @user information\"\"\"\n",
    "    tweet = re.sub('(RT\\s@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet)  # remove re-tweet\n",
    "    tweet = re.sub('(@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet)  # remove tweeted at\n",
    "    return tweet\n",
    "\n",
    "def remove_hashtags(tweet):\n",
    "    \"\"\"Takes a string and removes any hash tags\"\"\"\n",
    "    tweet = re.sub('(#[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet)  # remove hash tags\n",
    "    return tweet\n",
    "\n",
    "def remove_av(tweet):\n",
    "    \"\"\"Takes a string and removes AUDIO/VIDEO tags or labels\"\"\"\n",
    "    tweet = re.sub('VIDEO:', '', tweet)  # remove 'VIDEO:' from start of tweet\n",
    "    tweet = re.sub('AUDIO:', '', tweet)  # remove 'AUDIO:' from start of tweet\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T10:02:41.145233Z",
     "iopub.status.busy": "2022-05-13T10:02:41.144961Z",
     "iopub.status.idle": "2022-05-13T10:02:41.458458Z",
     "shell.execute_reply": "2022-05-13T10:02:41.456961Z",
     "shell.execute_reply.started": "2022-05-13T10:02:41.145204Z"
    }
   },
   "outputs": [],
   "source": [
    "df['OriginalTweet'] = df['OriginalTweet'].apply(remove_users)\n",
    "df['OriginalTweet'] = df['OriginalTweet'].apply(remove_av)\n",
    "df['OriginalTweet'] = df['OriginalTweet'].apply(remove_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T10:03:02.027146Z",
     "iopub.status.busy": "2022-05-13T10:03:02.025538Z",
     "iopub.status.idle": "2022-05-13T10:03:06.613377Z",
     "shell.execute_reply": "2022-05-13T10:03:06.612758Z",
     "shell.execute_reply.started": "2022-05-13T10:03:02.027063Z"
    }
   },
   "outputs": [],
   "source": [
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(df['OriginalTweet'].values)\n",
    "X = tokenizer.texts_to_sequences(df['OriginalTweet'].values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T10:03:09.224978Z",
     "iopub.status.busy": "2022-05-13T10:03:09.224562Z",
     "iopub.status.idle": "2022-05-13T10:03:09.249829Z",
     "shell.execute_reply": "2022-05-13T10:03:09.248993Z",
     "shell.execute_reply.started": "2022-05-13T10:03:09.224938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27575, 60) (27575, 5)\n",
      "(13582, 60) (13582, 5)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(df['Sentiment']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dl\">Deep Learning</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T10:03:15.433906Z",
     "iopub.status.busy": "2022-05-13T10:03:15.433659Z",
     "iopub.status.idle": "2022-05-13T10:03:15.748663Z",
     "shell.execute_reply": "2022-05-13T10:03:15.747313Z",
     "shell.execute_reply.started": "2022-05-13T10:03:15.433881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 60, 128)           256000    \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, 60, 128)          0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 196)               254800    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 985       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 511,785\n",
      "Trainable params: 511,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(5,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T10:27:15.329655Z",
     "iopub.status.busy": "2022-05-13T10:27:15.329314Z",
     "iopub.status.idle": "2022-05-13T10:27:15.408943Z",
     "shell.execute_reply": "2022-05-13T10:27:15.40787Z",
     "shell.execute_reply.started": "2022-05-13T10:27:15.329566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "862/862 [==============================] - 235s 268ms/step - loss: 1.2482 - accuracy: 0.4660\n",
      "Epoch 2/25\n",
      "862/862 [==============================] - 234s 271ms/step - loss: 0.9412 - accuracy: 0.6464\n",
      "Epoch 3/25\n",
      "862/862 [==============================] - 224s 260ms/step - loss: 0.8863 - accuracy: 0.6746\n",
      "Epoch 4/25\n",
      "862/862 [==============================] - 222s 258ms/step - loss: 0.8488 - accuracy: 0.6884\n",
      "Epoch 5/25\n",
      "862/862 [==============================] - 227s 263ms/step - loss: 0.8152 - accuracy: 0.6986\n",
      "Epoch 6/25\n",
      "862/862 [==============================] - 237s 275ms/step - loss: 0.7817 - accuracy: 0.7132\n",
      "Epoch 7/25\n",
      "862/862 [==============================] - 240s 279ms/step - loss: 0.7516 - accuracy: 0.7237\n",
      "Epoch 8/25\n",
      "862/862 [==============================] - 238s 276ms/step - loss: 0.7246 - accuracy: 0.7360\n",
      "Epoch 9/25\n",
      "862/862 [==============================] - 385s 446ms/step - loss: 0.6996 - accuracy: 0.7411\n",
      "Epoch 10/25\n",
      "862/862 [==============================] - 220s 256ms/step - loss: 0.6669 - accuracy: 0.7539\n",
      "Epoch 11/25\n",
      "862/862 [==============================] - 232s 269ms/step - loss: 0.6401 - accuracy: 0.7657\n",
      "Epoch 12/25\n",
      "862/862 [==============================] - 238s 277ms/step - loss: 0.6190 - accuracy: 0.7740\n",
      "Epoch 13/25\n",
      "862/862 [==============================] - 234s 272ms/step - loss: 0.5901 - accuracy: 0.7817\n",
      "Epoch 14/25\n",
      "862/862 [==============================] - 232s 269ms/step - loss: 0.5648 - accuracy: 0.7922\n",
      "Epoch 15/25\n",
      "862/862 [==============================] - 235s 272ms/step - loss: 0.5416 - accuracy: 0.8030\n",
      "Epoch 16/25\n",
      "862/862 [==============================] - 233s 270ms/step - loss: 0.5198 - accuracy: 0.8086\n",
      "Epoch 17/25\n",
      "862/862 [==============================] - 233s 270ms/step - loss: 0.4963 - accuracy: 0.8185\n",
      "Epoch 18/25\n",
      "862/862 [==============================] - 221s 256ms/step - loss: 0.4723 - accuracy: 0.8251\n",
      "Epoch 19/25\n",
      "862/862 [==============================] - 227s 263ms/step - loss: 0.4575 - accuracy: 0.8307\n",
      "Epoch 20/25\n",
      "862/862 [==============================] - 234s 271ms/step - loss: 0.4341 - accuracy: 0.8414\n",
      "Epoch 21/25\n",
      "862/862 [==============================] - 234s 272ms/step - loss: 0.4171 - accuracy: 0.8472\n",
      "Epoch 22/25\n",
      "862/862 [==============================] - 229s 265ms/step - loss: 0.4021 - accuracy: 0.8508\n",
      "Epoch 23/25\n",
      "862/862 [==============================] - 228s 264ms/step - loss: 0.3903 - accuracy: 0.8568\n",
      "Epoch 24/25\n",
      "862/862 [==============================] - 222s 257ms/step - loss: 0.3773 - accuracy: 0.8598\n",
      "Epoch 25/25\n",
      "862/862 [==============================] - 220s 255ms/step - loss: 0.3663 - accuracy: 0.8646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21b4381d280>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit(X_train, Y_train, epochs = 25, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"s\"></a>\n",
    "## Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"NLP_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
